{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9774bc28",
   "metadata": {},
   "source": [
    "---\n",
    "Packages required\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be318819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "\n",
    "from pyecharts.charts import Geo\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ChartType, SymbolType\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from typing import List, Set, Dict, Tuple, Union\n",
    "\n",
    "pd.set_option('display.max_rows',10)\n",
    "pd.set_option('display.min_rows',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ff171",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc0905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .dat file (assuming tab-separated values)\n",
    "airports = pd.read_csv('../data/airports.dat', sep=',',header = None, encoding='utf-8')  # Change separator as needed\n",
    "airports.columns = [\n",
    "    \"Airport ID\", \"Name\", \"City\", \"Country\", \n",
    "    \"IATA\", \"ICAO\", \"Latitude\", \"Longitude\", \n",
    "    \"Altitude\", \"Timezone\", \"DST\", \"Tz database time zone\", \n",
    "    \"Type\", \"Source\"\n",
    "]\n",
    "routes = pd.read_csv('../data/routes.dat', sep=',',header = None, encoding='utf-8')  # Change separator as needed\n",
    "routes.columns = [\n",
    "    \"Airline\", \"Airline ID\", \"Source airport\", \"Source airport ID\", \n",
    "    \"Destination airport\", \"Destination airport ID\", \"Codeshare\", \n",
    "    \"Stops\", \"Equipment\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74663f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>DST</th>\n",
       "      <th>Tz database time zone</th>\n",
       "      <th>Type</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Goroka Airport</td>\n",
       "      <td>Goroka</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>GKA</td>\n",
       "      <td>AYGA</td>\n",
       "      <td>-6.081690</td>\n",
       "      <td>145.391998</td>\n",
       "      <td>5282</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Madang Airport</td>\n",
       "      <td>Madang</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>MAG</td>\n",
       "      <td>AYMD</td>\n",
       "      <td>-5.207080</td>\n",
       "      <td>145.789001</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mount Hagen Kagamuga Airport</td>\n",
       "      <td>Mount Hagen</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>HGU</td>\n",
       "      <td>AYMH</td>\n",
       "      <td>-5.826790</td>\n",
       "      <td>144.296005</td>\n",
       "      <td>5388</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nadzab Airport</td>\n",
       "      <td>Nadzab</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>LAE</td>\n",
       "      <td>AYNZ</td>\n",
       "      <td>-6.569803</td>\n",
       "      <td>146.725977</td>\n",
       "      <td>239</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Port Moresby Jacksons International Airport</td>\n",
       "      <td>Port Moresby</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>POM</td>\n",
       "      <td>AYPY</td>\n",
       "      <td>-9.443380</td>\n",
       "      <td>147.220001</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Airport ID                                         Name          City  \\\n",
       "0           1                               Goroka Airport        Goroka   \n",
       "1           2                               Madang Airport        Madang   \n",
       "2           3                 Mount Hagen Kagamuga Airport   Mount Hagen   \n",
       "3           4                               Nadzab Airport        Nadzab   \n",
       "4           5  Port Moresby Jacksons International Airport  Port Moresby   \n",
       "\n",
       "            Country IATA  ICAO  Latitude   Longitude  Altitude Timezone DST  \\\n",
       "0  Papua New Guinea  GKA  AYGA -6.081690  145.391998      5282       10   U   \n",
       "1  Papua New Guinea  MAG  AYMD -5.207080  145.789001        20       10   U   \n",
       "2  Papua New Guinea  HGU  AYMH -5.826790  144.296005      5388       10   U   \n",
       "3  Papua New Guinea  LAE  AYNZ -6.569803  146.725977       239       10   U   \n",
       "4  Papua New Guinea  POM  AYPY -9.443380  147.220001       146       10   U   \n",
       "\n",
       "  Tz database time zone     Type       Source  \n",
       "0  Pacific/Port_Moresby  airport  OurAirports  \n",
       "1  Pacific/Port_Moresby  airport  OurAirports  \n",
       "2  Pacific/Port_Moresby  airport  OurAirports  \n",
       "3  Pacific/Port_Moresby  airport  OurAirports  \n",
       "4  Pacific/Port_Moresby  airport  OurAirports  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5e9ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Airline ID</th>\n",
       "      <th>Source airport</th>\n",
       "      <th>Source airport ID</th>\n",
       "      <th>Destination airport</th>\n",
       "      <th>Destination airport ID</th>\n",
       "      <th>Codeshare</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>AER</td>\n",
       "      <td>2965</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>MRV</td>\n",
       "      <td>2962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>OVB</td>\n",
       "      <td>4078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Airline Airline ID Source airport Source airport ID Destination airport  \\\n",
       "0      2B        410            AER              2965                 KZN   \n",
       "1      2B        410            ASF              2966                 KZN   \n",
       "2      2B        410            ASF              2966                 MRV   \n",
       "3      2B        410            CEK              2968                 KZN   \n",
       "4      2B        410            CEK              2968                 OVB   \n",
       "\n",
       "  Destination airport ID Codeshare  Stops Equipment  \n",
       "0                   2990       NaN      0       CR2  \n",
       "1                   2990       NaN      0       CR2  \n",
       "2                   2962       NaN      0       CR2  \n",
       "3                   2990       NaN      0       CR2  \n",
       "4                   4078       NaN      0       CR2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce00776c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated\n",
    "airports.duplicated().sum(), routes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36ea1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Airline ID</th>\n",
       "      <th>Source airport</th>\n",
       "      <th>Source airport ID</th>\n",
       "      <th>Destination airport</th>\n",
       "      <th>Destination airport ID</th>\n",
       "      <th>Codeshare</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Airline ID, Source airport, Source airport ID, Destination airport, Destination airport ID, Codeshare, Stops, Equipment]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[routes['Destination airport'].str.len() > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240e2d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Airline ID</th>\n",
       "      <th>Source airport</th>\n",
       "      <th>Source airport ID</th>\n",
       "      <th>Destination airport</th>\n",
       "      <th>Destination airport ID</th>\n",
       "      <th>Codeshare</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Airline ID, Source airport, Source airport ID, Destination airport, Destination airport ID, Codeshare, Stops, Equipment]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[routes['Source airport'].str.len() > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e22a0",
   "metadata": {},
   "source": [
    "All the aiports in routes use IATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac663c",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91d4e2",
   "metadata": {},
   "source": [
    "## Columns Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c61921",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_s = airports.loc[:,['IATA','Latitude','Longitude']]\n",
    "routes_s = routes.loc[:,['Source airport','Destination airport']]\n",
    "# Delete all airports without IATA\n",
    "airports_s = airports_s[airports_s['IATA']!='\\\\N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a312a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(IATA         0\n",
       " Latitude     0\n",
       " Longitude    0\n",
       " dtype: int64,\n",
       " Source airport         0\n",
       " Destination airport    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null\n",
    "airports_s.isnull().sum(), routes_s.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae1ccb",
   "metadata": {},
   "source": [
    "----------\n",
    "We select routes that had appeared n or more times, and select airports which is existed in the filtered route data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c5346",
   "metadata": {},
   "source": [
    "## Route counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324c83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of routes list: 1621\n"
     ]
    }
   ],
   "source": [
    "#  Count the number of times each route appears\n",
    "route_counts = routes_s.value_counts().reset_index()\n",
    "route_counts.columns = ['Source airport', 'Destination airport', 'Count']\n",
    "\n",
    "def filtered_routes_list(n,m=9999):\n",
    "    # save as [('Source airport','Destination airport')]\n",
    "    routes_list = [\n",
    "    (row['Source airport'], row['Destination airport'])\n",
    "    for _, row in route_counts[(route_counts['Count'] >= n) & (route_counts['Count'] < m)].iterrows()\n",
    "]\n",
    "    return routes_list\n",
    "\n",
    "def filtered_routes_dict(n,m=9999):\n",
    "    # save as {('Source airport','Destination airport'): count}\n",
    "    routes_dict = {\n",
    "    (row['Source airport'], row['Destination airport']): row['Count']\n",
    "    for _, row in route_counts[(route_counts['Count'] >= n) & (route_counts['Count'] < m)].iterrows()\n",
    "    }\n",
    "    return routes_dict\n",
    "\n",
    "routes_list = filtered_routes_list(5) # As the data is too big, we only choose routes that had appeared five or more times\n",
    "routes_dict = filtered_routes_dict(5)\n",
    "print(\"Length of routes list:\", len(routes_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df04b2",
   "metadata": {},
   "source": [
    "## Flight counts in each airport (filtered by routes selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11fcc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of flight counts list: 385\n"
     ]
    }
   ],
   "source": [
    "# Total takeoffs and landings at each airport\n",
    "departure_counts = route_counts.groupby('Source airport')['Count'].sum().rename('Departures')\n",
    "arrival_counts = route_counts.groupby('Destination airport')['Count'].sum().rename('Arrivals')\n",
    "flight_counts = pd.concat([departure_counts, arrival_counts], axis=1).fillna(0)\n",
    "\n",
    "def filtered_airports_counts_list(routes_list):\n",
    "    # Save as [('Airport'),flight counts]\n",
    "    \n",
    "    # Extract all airports involved in the routes_list, and filter airports in flight_counts that are not included in routes_list\n",
    "    filtered_flight_counts = flight_counts.loc[\n",
    "        flight_counts.index.intersection({airport for route in routes_list for airport in route})\n",
    "    ]\n",
    "    # Convert to pycharts input format\n",
    "    airports_counts_list = sorted(\n",
    "        [\n",
    "            (airport, int(departures + arrivals))\n",
    "            for airport, departures, arrivals in filtered_flight_counts.itertuples(index=True, name=None)\n",
    "        ],\n",
    "        key=lambda x: x[1],  # sort by total flights counts\n",
    "        reverse=True\n",
    "    )\n",
    "    return airports_counts_list\n",
    "\n",
    "airports_counts_list = filtered_airports_counts_list(filtered_routes_list(5))\n",
    "print(\"Length of flight counts list:\", len(airports_counts_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429e5ea",
   "metadata": {},
   "source": [
    "## Add coordinate points in Geo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c85206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(airports_s)):\n",
    "    Geo().add_coordinate(\n",
    "    name = airports_s.iloc[i,0],\n",
    "    latitude = airports_s.iloc[i,1],\n",
    "    longitude =  airports_s.iloc[i,2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8a70e",
   "metadata": {},
   "source": [
    "----\n",
    "Preliminary visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "306fadc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\Aiports&Routes.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "# Add airport scatter points\n",
    "c.add(\n",
    "    \"Airports\",\n",
    "    data_pair=airports_counts_list,  # e.g., a list of tuples [(\"ATL\", 100), (\"JFK\", 80), ...]\n",
    "    type_=ChartType.EFFECT_SCATTER,\n",
    "    color=\"red\",\n",
    "    symbol_size=3,\n",
    ")\n",
    "\n",
    "# Add airline routes for different ranges\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    color = f\"rgb({255 - 250/n*(i+1)},160, {250/n*(i+1)})\"\n",
    "    c.add(\n",
    "        f\"Airline routes - counts [{5+i*2},{7+i*2})\",\n",
    "        data_pair=filtered_routes_list(5+i*2, 7+i*2),  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity=0.4 + 0.6/n*i, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "# Add the left airline routes\n",
    "c.add(\n",
    "    f\"Airline routes - counts [{5+n*2},9999)\",\n",
    "    data_pair=filtered_routes_list(5+n*2),\n",
    "    type_=ChartType.LINES,\n",
    "    symbol_size = 0,\n",
    "    effect_opts=opts.EffectOpts(        \n",
    "        symbol=SymbolType.ARROW, symbol_size=3, color=\"blue\"\n",
    "    ),\n",
    "    linestyle_opts=opts.LineStyleOpts(width = 0.1, curve=0.4, color = \"blue\",opacity = 1, type_ = 'solid'),\n",
    ")\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=\"Aiport and Routes (Basic)\",pos_left = 'center'),                  \n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render('../echarts/RouteBased/Aiports&Routes.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649acc3a",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96c5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Community = nx.DiGraph()\n",
    "weighted_edges = [(u, v, weight) for (u, v), weight in routes_dict.items()]\n",
    "Community.add_weighted_edges_from(weighted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f453075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flight counts to each nodes\n",
    "def create_nodes_count(nodes):\n",
    "    nodes_count = {}\n",
    "    for key in nodes.keys():\n",
    "        nodes_count[key] = [\n",
    "            (airport,count)\n",
    "            for airport,count in airports_counts_list\n",
    "            if airport in nodes[key]\n",
    "        ]\n",
    "    return nodes_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508dd58d",
   "metadata": {},
   "source": [
    "## Clique detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "036ad924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all cliques in the graph\n",
    "undirected_community = Community.to_undirected()\n",
    "cliques = list(nx.find_cliques(undirected_community))\n",
    "# cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9af31",
   "metadata": {},
   "source": [
    "### Clique data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b31a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the nodes by clique size\n",
    "clique_nodes = {}\n",
    "\n",
    "# Iterate through each detected clique\n",
    "for clique in cliques:\n",
    "    clique_length = len(clique)  # Get the size of the clique\n",
    "    \n",
    "    # If the clique length is already a key, add the nodes to the list of nodes for this length\n",
    "    cli = clique.copy()\n",
    "    if clique_length in clique_nodes:\n",
    "        clique_nodes[clique_length] += cli\n",
    "    else:\n",
    "        clique_nodes[clique_length] = cli\n",
    "\n",
    "# Remove duplicates by converting each list to a set and then back to a list\n",
    "for length in clique_nodes:\n",
    "    clique_nodes[length] = list(set(clique_nodes[length]))\n",
    "\n",
    "clique_nodes = dict(sorted(clique_nodes.items()))\n",
    "# clique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a9c1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "clique_nodes_count = create_nodes_count(clique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e324c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming clique_length_nodes contains the cliques by length, and routes_list contains routes\n",
    "clique_routes = {}\n",
    "\n",
    "# Iterate through each route in routes_list\n",
    "for route in routes_list:\n",
    "    source_airport, destination_airport = route\n",
    "\n",
    "    # Initialize variable to store the maximum clique length where both airports belong\n",
    "    max_clique_length = -1\n",
    "\n",
    "    # Check which clique length both airports belong to\n",
    "    for clique_length, nodes in clique_nodes.items():\n",
    "        if source_airport in nodes and destination_airport in nodes:\n",
    "            max_clique_length = max(max_clique_length, clique_length)\n",
    "\n",
    "    # If both airports are found in a clique, add the route to the corresponding clique length\n",
    "    if max_clique_length != -1:\n",
    "        if max_clique_length not in clique_routes:\n",
    "            clique_routes[max_clique_length] = []\n",
    "        clique_routes[max_clique_length].append(route)\n",
    "\n",
    "clique_routes = dict(sorted(clique_routes.items()))\n",
    "# clique_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e9221",
   "metadata": {},
   "source": [
    "### Draw Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7742d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\cliques.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(clique_nodes.keys())\n",
    "L_e = len(clique_routes.keys())\n",
    "\n",
    "# Add airport scatter points\n",
    "for i, key in enumerate(clique_nodes.keys()):\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports {key}-clique\",\n",
    "        data_pair=clique_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "\n",
    "for i, key in enumerate(clique_routes.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({255 - 250*rate},160, {250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes {key}-clique\",\n",
    "        data_pair=clique_routes[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity=0.4 + 0.6*rate, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=\"Aiport and Routes (Cliques)\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render('../echarts/RouteBased/cliques.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334b5bb",
   "metadata": {},
   "source": [
    "## K-cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc8f08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cores(G):\n",
    "    k = 1\n",
    "    k_cores_nodes = {}\n",
    "    k_cores_edges = {}\n",
    "    while True:\n",
    "        # Compute k-core for the current value of k\n",
    "        k_core = nx.k_core(G, k=k)\n",
    "        \n",
    "        # If no nodes are left, stop\n",
    "        if not k_core.nodes:\n",
    "            k -= 1\n",
    "            break\n",
    "        \n",
    "        # Store nodes and edges of the current k-core\n",
    "        k_cores_nodes[k] = list(k_core.nodes)\n",
    "        k_cores_edges[k] = list(k_core.edges)\n",
    "        \n",
    "        #-------This section is to reduce the size of the image, but will be little different from the result of kcore\n",
    "        # Subtract previous k-cores' nodes and edges\n",
    "        if k > 1:\n",
    "            k_cores_nodes[k-1] = list(set(k_cores_nodes[k-1]) - set(k_cores_nodes[k]))\n",
    "            k_cores_edges[k-1] = list(set(k_cores_edges[k-1]) - set(k_cores_edges[k]))\n",
    "            if k_cores_nodes[k-1] == [] and k_cores_edges[k-1] == []:\n",
    "                del k_cores_nodes[k-1]\n",
    "                del k_cores_edges[k-1]\n",
    "        k += 1  # Increment k for the next iteration\n",
    "\n",
    "    return k, k_cores_nodes, k_cores_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a096c2",
   "metadata": {},
   "source": [
    "###  K-cores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173f4a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-k: 18\n"
     ]
    }
   ],
   "source": [
    "k, k_nodes, k_edges = k_cores(Community)\n",
    "print('Max-k:',k)\n",
    "# print(\"K-Cores (Nodes):\", k_nodes)\n",
    "# print(\"K-Cores (Edges):\", k_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "403367d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nodes_count = create_nodes_count(k_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44d6e9",
   "metadata": {},
   "source": [
    "### Draw K-cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da922a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\k-cores.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(k_nodes.keys())\n",
    "L_e = len(k_edges.keys())\n",
    "\n",
    "for i, key in enumerate(k_nodes.keys()):\n",
    "    # Add airport scatter points\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports {key}-core\",\n",
    "        data_pair=k_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "\n",
    "for i, key in enumerate(k_edges.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({255 - 250*rate},160, {250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes {key}-core\",\n",
    "        data_pair=k_edges[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity=0.4 + 0.6*rate, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=\"Aiport and Routes (K-cores)\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render('../echarts/RouteBased/k-cores.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0eace",
   "metadata": {},
   "source": [
    "## SNN - Shared Near Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0f48d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSN:\n",
    "    def __init__(self, snn_routes: Dict[Tuple[str, str], int], method = 'mixed'):\n",
    "        '''\n",
    "        Initialize Jarvis-Patrick clustering.\n",
    "        Parameters:\n",
    "        - snn_routes: A dictionary of route counts with keys as (source, destination)\n",
    "        - method: How similarity is calculated ('source', 'destination', or 'mixed').\n",
    "            'source': similarity calculate by route counts from source airports - only forth\n",
    "            'destination': similarity calculate by route counts to destination airports - only back\n",
    "            'mixed': similarity calculate by aggregate route counts - both back and forth\n",
    "        '''\n",
    "        if method not in ('source', 'destination', 'mixed'):\n",
    "            raise ValueError(\"Invalid method. Choose from 'source', 'destination', 'mixed'.\")\n",
    "        self.method = method\n",
    "        self.snn_routes = snn_routes.copy()\n",
    "        self.similarity_df = None\n",
    "        \n",
    "    def similarity_matrix_calu(self):\n",
    "        \"\"\"Calculate the similarity matrix based on the chosen method.\"\"\"\n",
    "        # Extract unique airports\n",
    "        snn_airports = list(set([airport for route in self.snn_routes.keys() for airport in route]))\n",
    "        airport_index = {airport: idx for idx, airport in enumerate(snn_airports)}\n",
    "        \n",
    "        # Initialize similarity matrix\n",
    "        similarity_matrix = np.zeros((len(snn_airports), len(snn_airports)), dtype=int)\n",
    "\n",
    "        # Fill similarity matrix\n",
    "        for (source, destination), count in self.snn_routes.items():\n",
    "            i, j = airport_index[source], airport_index[destination]\n",
    "            if self.method == 'source':\n",
    "                similarity_matrix[i, j] = count\n",
    "            elif self.method == 'destination':\n",
    "                similarity_matrix[j, i] = count\n",
    "            elif self.method == 'mixed':\n",
    "                similarity_matrix[i, j] += count\n",
    "                similarity_matrix[j, i] += count\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        self.similarity_df = pd.DataFrame(similarity_matrix, index=snn_airports, columns=snn_airports)\n",
    "\n",
    "    def non_zero_similarity(self):\n",
    "        \"\"\"Generate descriptive statistics for non-zero similarities.\"\"\"\n",
    "        if self.similarity_df is None:\n",
    "            self.similarity_matrix_calu()\n",
    "        non_zero_counts = (self.similarity_df != 0).sum()\n",
    "        return non_zero_counts\n",
    "            \n",
    "            \n",
    "    def jp_cluster_calu(self,k=3, T1=2, T2=1):\n",
    "        \"\"\"\n",
    "        Perform Jarvis-Patrick clustering based on SNN similarity.\n",
    "\n",
    "        Parameters:\n",
    "        - k: Number of nearest neighbors to consider.\n",
    "        - T1: Minimum shared neighbors for clustering.\n",
    "        - T2: Minimum similarity score for clustering.\n",
    "\n",
    "        Returns:\n",
    "        - clusters: A dictionary with cluster indices and members.\n",
    "        \"\"\"\n",
    "        if self.similarity_df is None:\n",
    "            self.similarity_matrix_calu()\n",
    "\n",
    "        # Find k-nearest neighbors for each airport\n",
    "        neighbors = {\n",
    "            airport: self.similarity_df.loc[airport]\n",
    "            .nlargest(k + 1)  # Include self\n",
    "            .iloc[1:]         # Exclude self\n",
    "            .index.tolist()\n",
    "            for airport in self.similarity_df.index\n",
    "        }\n",
    "        self.neighbors = neighbors \n",
    "        \n",
    "        # Build graph based on shared neighbors and similarity thresholds\n",
    "        G = nx.Graph()\n",
    "        for airport, neighbor_list in neighbors.items():\n",
    "            for neighbor in neighbor_list:\n",
    "                shared_neighbors = len(set(neighbors[airport]) & set(neighbors[neighbor]))\n",
    "                if shared_neighbors >= T1 and self.similarity_df.loc[airport, neighbor] >= T2:\n",
    "                    G.add_edge(airport, neighbor)\n",
    "\n",
    "        # Find connected components (clusters)\n",
    "        self.clusters = {i: list(c) for i, c in enumerate(nx.connected_components(G))}\n",
    "        return self.clusters\n",
    "    \n",
    "    def create_snn_nodes_count(self,airports_counts_list):\n",
    "        '''create nodes data for pyechart'''\n",
    "        try: \n",
    "            self.clusters\n",
    "        except:\n",
    "            raise ValueError(\"Run .jp_cluster_calu() first.\")\n",
    "            \n",
    "        snn_nodes = [airport for cluster in self.clusters.values() for airport in cluster]\n",
    "        snn_nodes_count = [\n",
    "            (airport,count)\n",
    "            for airport,count in airports_counts_list\n",
    "            if airport in snn_nodes\n",
    "        ]\n",
    "        return snn_nodes_count\n",
    "    \n",
    "    def create_snn_edges(self):\n",
    "        '''create edges data for pyechart'''\n",
    "        try:\n",
    "            self.clusters\n",
    "        except:\n",
    "            raise ValueError(\"Run .jp_cluster_calu() first.\")\n",
    "\n",
    "        snn_edges = [\n",
    "            route\n",
    "            for cluster in self.clusters.values()\n",
    "            for route in (combinations(cluster, 2))\n",
    "        ]\n",
    "        return snn_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "037d985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    385.000000\n",
      "mean       4.425974\n",
      "std        6.940998\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        5.000000\n",
      "max       79.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''test'''\n",
    "snn = SSN(snn_routes = routes_dict, method = 'mixed')\n",
    "JP_clusters = snn.jp_cluster_calu(k=5, T1=2, T2=5)\n",
    "print(snn.non_zero_similarity().describe())\n",
    "# print(\"JP_clusters:\",JP_clusters)\n",
    "# print(snn.create_snn_nodes_count(airports_counts_list))\n",
    "# print(snn.create_snn_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4268ba",
   "metadata": {},
   "source": [
    "### SNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf56be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_s = SSN(snn_routes = routes_dict, method = 'source')\n",
    "snn_s_clts = snn_s.jp_cluster_calu(k=5, T1=2, T2=1)\n",
    "snn_s_ngbs = snn_s.neighbors\n",
    "\n",
    "snn_d = SSN(snn_routes = routes_dict, method = 'destination')\n",
    "snn_d_clts = snn_d.jp_cluster_calu(k=5, T1=2, T2=1)\n",
    "snn_d_ngbs = snn_d.neighbors\n",
    "\n",
    "snn_m = SSN(snn_routes = routes_dict, method = 'mixed')\n",
    "snn_m_clts = snn_m.jp_cluster_calu(k=5, T1=2, T2=1)\n",
    "snn_m_ngbs = snn_m.neighbors\n",
    "\n",
    "snn_nodes_count = {\n",
    "    'source':snn_s.create_snn_nodes_count(airports_counts_list),\n",
    "    'destination':snn_d.create_snn_nodes_count(airports_counts_list),\n",
    "    'mixed':snn_m.create_snn_nodes_count(airports_counts_list)\n",
    "}\n",
    "snn_edges = {\n",
    "    'source':snn_s.create_snn_edges(),\n",
    "    'destination':snn_d.create_snn_edges(),\n",
    "    'mixed':snn_m.create_snn_edges()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86826b95",
   "metadata": {},
   "source": [
    "###  Draw SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5144fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\snn.html'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(snn_nodes_count.keys())\n",
    "L_e = len(snn_edges.keys())\n",
    "\n",
    "for i, key in enumerate(snn_nodes_count.keys()):\n",
    "    # Add airport scatter points\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports SNN-{key}\",\n",
    "        data_pair=snn_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "    \n",
    "for i, key in enumerate(snn_edges.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({255 - 250*rate},160, {250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes SNN-{key}\",\n",
    "        data_pair=snn_edges[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=0, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.2, curve=0, opacity=1, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=\"Aiport and Routes (K-cores)\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render('../echarts/RouteBased/snn.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7281c6",
   "metadata": {},
   "source": [
    "## IHCS - Iterated Highly Connected Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e823633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IHCS:\n",
    "    \"\"\"\n",
    "    Iterated Highly Connected Subgraphs (IHCS) clustering algorithm implementation.\n",
    "    Based on: \"Hartuv, E., & Shamir, R. (2000). A clustering algorithm based on graph connectivity\"\n",
    "    \n",
    "    The Iterated HCS version repeatedly applies HCS until convergence.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_cluster_size=3):\n",
    "        \"\"\"\n",
    "        Initialize IHCS clustering algorithm.\n",
    "        \n",
    "        Args:\n",
    "            min_cluster_size (int): Minimum number of nodes in a cluster (default: 3)\n",
    "        \"\"\"\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "        self.labels = {}\n",
    "        self.clusters = {}\n",
    "        \n",
    "    def fit(self, graph):\n",
    "        \"\"\"\n",
    "        Perform IHCS clustering on the input graph.\n",
    "        \n",
    "        Args:\n",
    "            graph (nx.Graph): Input graph to be clustered\n",
    "            \n",
    "        Returns:\n",
    "            dict: Cluster labels for each node\n",
    "        \"\"\"\n",
    "        self.graph = graph.copy()\n",
    "        \n",
    "        if self.graph is None or len(self.graph) == 0:\n",
    "            raise ValueError(\"No graph provided for clustering\")\n",
    "        \n",
    "        # Initial clustering\n",
    "        clustered_graph = self._ihcs_recursive(self.graph)\n",
    "        \n",
    "        # Assign labels and group clusters\n",
    "        self._assign_cluster_labels(clustered_graph)\n",
    "        self._group_clusters()\n",
    "        \n",
    "        return self.labels\n",
    "    \n",
    "    def _is_highly_connected(self, graph):\n",
    "        \"\"\"\n",
    "        Check if a graph is highly connected using edge connectivity.\n",
    "        A graph is highly connected if its edge connectivity is greater than |V|/2.\n",
    "        \"\"\"\n",
    "        n = len(graph)\n",
    "        if n <= 1:\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            edge_connectivity = nx.edge_connectivity(graph)\n",
    "            return edge_connectivity > n/2\n",
    "        except nx.NetworkXError:\n",
    "            return False\n",
    "            \n",
    "    def _get_minimum_cut(self, graph):\n",
    "        \"\"\"Get the minimum cut of a graph\"\"\"\n",
    "        try:\n",
    "            return nx.minimum_edge_cut(graph)\n",
    "        except nx.NetworkXError:\n",
    "            return set()\n",
    "    \n",
    "    def _remove_edges(self, graph, edges):\n",
    "        \"\"\"Remove edges from graph\"\"\"\n",
    "        graph_copy = graph.copy()\n",
    "        graph_copy.remove_edges_from(edges)\n",
    "        return graph_copy\n",
    "    \n",
    "    def _ihcs_recursive(self, graph):\n",
    "        \"\"\"\n",
    "        Recursive implementation of the Iterated HCS algorithm.\n",
    "        \n",
    "        Args:\n",
    "            graph (nx.Graph: Input graph to be processed\n",
    "            \n",
    "        Returns:\n",
    "            nx.Graph: Processed graph with final clustering\n",
    "        \"\"\"\n",
    "        # Base cases\n",
    "        if len(graph) < self.min_cluster_size:\n",
    "            return graph\n",
    "            \n",
    "        if not nx.is_connected(graph):\n",
    "            # Process each component separately\n",
    "            components = [graph.subgraph(c).copy() for c in nx.connected_components(graph)]\n",
    "            result = nx.Graph()\n",
    "            for component in components:\n",
    "                if len(component) >= self.min_cluster_size:\n",
    "                    result = nx.compose(result, self._ihcs_recursive(component))\n",
    "                else:\n",
    "                    result = nx.compose(result, component)\n",
    "            return result\n",
    "        \n",
    "        # Check if current graph is highly connected\n",
    "        if self._is_highly_connected(graph):\n",
    "            return graph\n",
    "            \n",
    "        # If not highly connected, find minimum cut and split\n",
    "        min_cut = self._get_minimum_cut(graph)\n",
    "        if not min_cut:\n",
    "            return graph\n",
    "            \n",
    "        # Split graph and recursively process subgraphs\n",
    "        split_graph = self._remove_edges(graph, min_cut)\n",
    "        subgraphs = [split_graph.subgraph(c).copy() for c in nx.connected_components(split_graph)]\n",
    "        \n",
    "        # Process each subgraph\n",
    "        result = nx.Graph()\n",
    "        for subgraph in subgraphs:\n",
    "            if len(subgraph) >= self.min_cluster_size:\n",
    "                processed_subgraph = self._ihcs_recursive(subgraph)\n",
    "                result = nx.compose(result, processed_subgraph)\n",
    "            else:\n",
    "                result = nx.compose(result, subgraph)\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    def _assign_cluster_labels(self, graph):\n",
    "        \"\"\"Assign cluster labels to nodes based on connected components\"\"\"\n",
    "        self.labels = {}\n",
    "        for cluster_idx, component in enumerate(nx.connected_components(graph), 1):\n",
    "            if len(component) >= self.min_cluster_size:\n",
    "                for node in component:\n",
    "                    self.labels[node] = cluster_idx\n",
    "            else:\n",
    "                # Assign small components to cluster 0 (outliers)\n",
    "                for node in component:\n",
    "                    self.labels[node] = 0\n",
    "    \n",
    "    def _group_clusters(self):\n",
    "        \"\"\"\n",
    "        Group nodes by their cluster labels.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary where keys are cluster labels and values are lists of nodes\n",
    "        \"\"\"\n",
    "        self.clusters = defaultdict(list)\n",
    "        for node, label in self.labels.items():\n",
    "            if label == 0:\n",
    "                self.clusters['Singletons'].append(node)\n",
    "            else: \n",
    "                self.clusters[f'Subgraph-{label}'].append(node)\n",
    "        return self.clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc329508",
   "metadata": {},
   "source": [
    "### IHCS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f6d82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: defaultdict(<class 'list'>, {'Singletons': ['ORD', 'BKK', 'HKG', 'NKG', 'TAO', 'HAK', 'CGO', 'KWL', 'DLC', 'TNA', 'HRB', 'SYX', 'FOC', 'SHE', 'NRT', 'ICN', 'TPE', 'SIN', 'NNG', 'LAX', 'SFO', 'JFK', 'LHR', 'ATL', 'SEA', 'YYZ', 'MSP', 'DFW', 'DEN', 'MSY', 'CGQ', 'LJG', 'URC', 'YUL', 'CDG', 'MEX', 'MIA', 'KIX', 'PHX', 'XNN', 'YVR', 'BOM', 'DEL', 'MAA', 'HYD', 'BLR', 'FCO', 'LGA', 'DTW', 'FRA', 'MAD', 'LIS', 'BRU', 'BCN', 'BOS', 'HNL', 'SYD', 'CUN', 'LAS', 'MAN', 'LGW', 'AGP', 'VIE', 'MUC', 'OPO', 'AUH', 'AMS', 'MXP', 'MNL', 'MCO', 'EWR', 'PMI', 'PUS', 'CTA', 'DUS', 'AYT', 'PRG', 'CGN', 'TXL', 'ARN', 'CPH', 'COK', 'ACE', 'FUE', 'BHX', 'TFS', 'HKT', 'KUL', 'MEL', 'PER', 'DPS', 'DXB', 'BAH', 'DOH', 'PNQ', 'CCU', 'DAC', 'LPA', 'PHL', 'LHW', 'HFE', 'BNE', 'ADL', 'EMA', 'IAD', 'CGK', 'NGB', 'AKL', 'SLC', 'IAH', 'LCA', 'ATH', 'GDL', 'MTY', 'SAN', 'WNZ', 'INC', 'IXZ', 'YYC', 'JED', 'KWI', 'DUB', 'EDI', 'BNA', 'HBE', 'MCT', 'YNT', 'BRS', 'CLO', 'BOG', 'LIM', 'SCL', 'AMD', 'HEL', 'JOG', 'RDU', 'JHG', 'CMB', 'TFN', 'FLL', 'TPA', 'ALC', 'TUS', 'SJU', 'WAW', 'PFO', 'AUS', 'SUB', 'SJW', 'FUK', 'PDX', 'DLM', 'HAM', 'ORY', 'CNS', 'SJD', 'KBL', 'HET', 'HLD', 'GAU', 'LXA', 'SMF', 'ZRH', 'CEB', 'HER', 'NGO', 'IXB', 'STL', 'OGG', 'GOI', 'GVA', 'TYN', 'WLG', 'KHN', 'ABQ', 'SSH', 'LKO', 'HND', 'RUH', 'SKG', 'GMP', 'MLE', 'MDE', 'IXR', 'LHE', 'MAR', 'CCS', 'AUA', 'CNX', 'PEN', 'NAG', 'MFM', 'VQS', 'JNB', 'CPT', 'CJB', 'PSP', 'ORF', 'TLS', 'IXA', 'HOU', 'SXR', 'KBV', 'MVD', 'PPT', 'CTS', 'SDJ', 'XNA', 'PIT', 'TIA', 'VRN', 'IDR', 'KHG', 'OSL', 'PMV', 'DKR', 'BKO', 'RGN', 'WDH', 'PAT', 'DMM', 'CVG', 'CHS', 'BDL', 'SAT', 'RSW', 'RNO', 'CEI', 'IBZ', 'OTP', 'JAN', 'MRS', 'DRW', 'GLA', 'CMH', 'YEG', 'YZF', 'GSO', 'VNS', 'CJU', 'DLA', 'NSI', 'ELP', 'ABZ', 'JAI', 'BHM', 'SJC', 'RIC', 'BPN', 'ISB', 'HSV', 'STT', 'PNS', 'PPS', 'AQP', 'CUZ', 'BEG', 'JZH', 'EBB', 'OKC', 'FIH', 'ALG', 'GSP', 'FRU', 'DME', 'TIV', 'LED', 'SVQ', 'DBV', 'VLC', 'SRQ', 'BDO', 'ALB', 'DAR', 'JRO', 'CAK', 'PKU', 'FAO', 'MCI', 'STR', 'OKA', 'MKE', 'JAX', 'OSS', 'BKI', 'GUA', 'TYS', 'ADD', 'TSA', 'KTM', 'CLT', 'PBI', 'KLO', 'CZM', 'ZUH', 'SGN', 'KOA', 'SDF', 'FLR', 'LGK', 'CHA', 'IXJ', 'MDW', 'MEM', 'CKY', 'PVR', 'CMN', 'DAY', 'RAK', 'TRV', 'SAV', 'CHC', 'LYS', 'HTN', 'SSG', 'PNH', 'CLE', 'LIH', 'BWI', 'VVO', 'IND', 'PTY', 'IXE', 'KHH', 'DCA', 'HRG', 'HRE', 'LUN', 'LLW', 'LOS', 'ACC', 'LFW', 'ABJ', 'OUA', 'NIM', 'COO', 'GYE', 'UIO', 'FNA', 'ROB', 'YWK', 'YZV', 'LPB', 'VVI', 'BEL', 'STM', 'MAO', 'SLU', 'FDF', 'PTP', 'TUN', 'TIP', 'IKA', 'IST', 'CWB', 'POA', 'ALA', 'TSE', 'SVX', 'OVB', 'DZA', 'HAH', 'SXM', 'DOM'], 'Subgraph-4': ['CSX', 'CTU', 'XIY', 'XMN', 'SHA', 'PVG', 'HGH', 'WUH', 'KMG', 'KWE', 'CKG', 'PEK', 'SZX', 'CAN', 'TSN'], 'Subgraph-130': ['GRU', 'EZE', 'GIG'], 'Subgraph-260': ['NBO', 'BJM', 'KGL']})\n"
     ]
    }
   ],
   "source": [
    "# Create IHCS object with minimum cluster size\n",
    "ihcs = IHCS(min_cluster_size=3)\n",
    "undirected_community = Community.to_undirected()\n",
    "ihcs.fit(undirected_community)\n",
    "\n",
    "# Get clustering results\n",
    "ihcs_nodes = ihcs.clusters\n",
    "print(\"Clusters:\", ihcs_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3755d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihcs_nodes_count = create_nodes_count(ihcs_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d243a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihcs_edges = defaultdict(list)\n",
    "ihcs_edges['Singletons'] = []\n",
    "for route in routes_list:\n",
    "    source, destination = route\n",
    "    for key, cluster in ihcs_nodes.items():\n",
    "        if key != 'Singletons':\n",
    "            if source in cluster and destination in cluster:\n",
    "                ihcs_edges[key].append(route)\n",
    "ihcs_edges['Singletons'] += list(set(routes_list)-set([edge for cluster in ihcs_edges.values() for edge in cluster]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f901a2",
   "metadata": {},
   "source": [
    "### Draw IHCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67a0f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\ihcs.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(ihcs_nodes.keys())\n",
    "L_e = len(ihcs_edges.keys())\n",
    "\n",
    "for i, key in enumerate(ihcs_nodes.keys()):\n",
    "    # Add airport scatter points\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports {key}\",\n",
    "        data_pair=ihcs_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "\n",
    "for i, key in enumerate(ihcs_edges.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({255 - 250*rate},160, {250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes {key}\",\n",
    "        data_pair=ihcs_edges[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity=0.2 + 0.8*rate, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=\"Aiport and Routes (ICHS)\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render('../echarts/RouteBased/ihcs.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd351c6",
   "metadata": {},
   "source": [
    "## LCMA - Local Clique Merging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c810c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCMA:\n",
    "    \"\"\"\n",
    "    Local Clique Merging Algorithm (LCMA) for analyzing and clustering route networks.\n",
    "    \n",
    "    This class implements a graph-based approach to identify and analyze clusters of highly\n",
    "    connected routes in transportation networks. It uses clique detection and merging\n",
    "    strategies to identify meaningful route groups while considering edge weights.\n",
    "    \n",
    "    The algorithm works in three main steps:\n",
    "    1. Convert route data into a weighted graph\n",
    "    2. Identify maximal cliques in the graph\n",
    "    3. Merge similar cliques based on a similarity threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.5, min_clique_size: int = 3, method = 'undirected'):\n",
    "        \"\"\"\n",
    "        Initialize LCMA router\n",
    "        \n",
    "        Args:\n",
    "            similarity_threshold: Threshold for merging cliques (0.0 to 1.0)\n",
    "            min_clique_size: Minimum size for considering a clique\n",
    "            method: Graph type to use for analysis. Options are:\n",
    "                - 'undirected': Treats routes as bidirectional\n",
    "                - 'directed': Preserves route directionality\n",
    "        \"\"\"\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.min_clique_size = min_clique_size\n",
    "        self.graph = None\n",
    "        self.cliques = []\n",
    "        self.clusters = []\n",
    "        self.method = method\n",
    "        \n",
    "    def _create_route_graph(self, routes: Dict[Tuple[str, str], float]) -> Union[nx.Graph, nx.DiGraph]:\n",
    "        \"\"\"\n",
    "        Create a graph from route dictionary\n",
    "        \n",
    "        Args:\n",
    "            routes: Dictionary with (origin, destination) tuples as keys and weights as values\n",
    "            \n",
    "        Returns:\n",
    "        NetworkX graph, either:\n",
    "        - nx.Graph if self.method == 'undirected'\n",
    "        - nx.DiGraph if self.method == 'directed'\n",
    "        \"\"\"\n",
    "        if self.method == 'undirected':\n",
    "            G = nx.Graph()\n",
    "        if self.method == 'directed':\n",
    "            G = nx.DiGraph()\n",
    "        for (origin, dest), weight in routes.items():\n",
    "            # Add edge with weight. If edge exists, use maximum weight\n",
    "            if G.has_edge(origin, dest):\n",
    "                G[origin][dest]['weight'] = max(G[origin][dest]['weight'], weight)\n",
    "            else:\n",
    "                G.add_edge(origin, dest, weight=weight)\n",
    "        return G\n",
    "    \n",
    "    def _find_maximal_cliques(self) -> List[Set[str]]:\n",
    "        \"\"\"\n",
    "        Find all maximal cliques in the route graph\n",
    "        \n",
    "        Returns:\n",
    "            List of sets containing nodes in each clique\n",
    "        \"\"\"\n",
    "        if self.method == 'undirected':\n",
    "            all_cliques = list(nx.find_cliques(self.graph))\n",
    "        if self.method == 'directed':\n",
    "            # Convert to undirected for clique finding, as cliques are undefined in directed graphs\n",
    "            all_cliques = list(nx.find_cliques(self.graph.to_undirected()))\n",
    "        return [set(c) for c in all_cliques if len(c) >= self.min_clique_size]\n",
    "    \n",
    "    def _calculate_clique_similarity(self, clique1: Set[str], clique2: Set[str]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate similarity between two cliques using weighted Jaccard coefficient\n",
    "        \n",
    "        Args:\n",
    "            clique1: First clique\n",
    "            clique2: Second clique\n",
    "            \n",
    "        Similarity score between 0 and 1, where:\n",
    "            - 0 indicates completely distinct cliques\n",
    "            - 1 indicates identical cliques with maximum edge weights\n",
    "        \"\"\"\n",
    "        intersection = len(clique1.intersection(clique2))\n",
    "        union = len(clique1.union(clique2))\n",
    "        \n",
    "        # Include edge weights in similarity calculation\n",
    "        if intersection > 0:\n",
    "            subgraph1 = self.graph.subgraph(clique1)\n",
    "            subgraph2 = self.graph.subgraph(clique2)\n",
    "            avg_weight1 = np.mean([d['weight'] for _, _, d in subgraph1.edges(data=True)])\n",
    "            avg_weight2 = np.mean([d['weight'] for _, _, d in subgraph2.edges(data=True)])\n",
    "            weight_factor = (avg_weight1 + avg_weight2) / 2 / 20  # Normalize by max weight\n",
    "            return (intersection / union) * (1 + weight_factor)\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def _merge_similar_cliques(self, cliques: List[Set[str]]) -> List[Set[str]]:\n",
    "        \"\"\"\n",
    "        Merge cliques that have similarity above threshold\n",
    "        \n",
    "        Args:\n",
    "            cliques: List of cliques to merge\n",
    "            \n",
    "        Returns:\n",
    "            List of merged cliques\n",
    "        \"\"\"\n",
    "        merged = True\n",
    "        while merged:\n",
    "            merged = False\n",
    "            for i, j in combinations(range(len(cliques)), 2):\n",
    "                if i < len(cliques) and j < len(cliques):\n",
    "                    similarity = self._calculate_clique_similarity(cliques[i], cliques[j])\n",
    "                    if similarity >= self.similarity_threshold:\n",
    "                        cliques[i] = cliques[i].union(cliques[j])\n",
    "                        cliques.pop(j)\n",
    "                        merged = True\n",
    "                        break\n",
    "        return cliques\n",
    "    \n",
    "    def _analyze_cluster_connectivity(self, cluster: Set[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze connectivity patterns within a cluster\n",
    "        \n",
    "        Args:\n",
    "            cluster: Set of nodes in the cluster\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing connectivity metrics\n",
    "        \"\"\"\n",
    "        subgraph = self.graph.subgraph(cluster)\n",
    "        edges = subgraph.edges(data=True)\n",
    "        weights = [d['weight'] for _, _, d in edges]\n",
    "        \n",
    "        return {\n",
    "            'size': len(cluster),\n",
    "            'density': nx.density(subgraph),\n",
    "            'avg_degree': sum(dict(subgraph.degree()).values()) / len(cluster),\n",
    "            'avg_weight': np.mean(weights) if weights else 0,\n",
    "            'max_weight': max(weights) if weights else 0,\n",
    "            'total_flights': sum(weights) if weights else 0\n",
    "        }\n",
    "    \n",
    "    def find_route_clusters(self, routes: Dict[Tuple[str, str], float]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Main method to find and analyze route clusters\n",
    "        \n",
    "        Args:\n",
    "            routes: Dictionary with (origin, destination) tuples as keys and weights as values\n",
    "            \n",
    "        Returns:\n",
    "            List of cluster information dictionaries\n",
    "        \"\"\"\n",
    "        self.graph = self._create_route_graph(routes)\n",
    "        self.cliques = self._find_maximal_cliques()\n",
    "        self.clusters = self._merge_similar_cliques(self.cliques)\n",
    "        \n",
    "        cluster_info = []\n",
    "        for i, cluster in enumerate(self.clusters):\n",
    "            info = {\n",
    "                'cluster_id': i,\n",
    "                'nodes': list(cluster),\n",
    "                'metrics': self._analyze_cluster_connectivity(cluster)\n",
    "            }\n",
    "            cluster_info.append(info)\n",
    "        \n",
    "        return cluster_info\n",
    "    \n",
    "    def get_cluster_routes(self, cluster: Set[str]) -> Dict[Tuple[str, str], float]:\n",
    "        \"\"\"\n",
    "        Get all routes within a cluster\n",
    "        \n",
    "        Args:\n",
    "            cluster: Set of nodes in the cluster\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of routes with weights\n",
    "        \"\"\"\n",
    "        subgraph = self.graph.subgraph(cluster)\n",
    "        routes = {}\n",
    "        for origin, dest, data in subgraph.edges(data=True):\n",
    "            routes[(origin, dest)] = data['weight']\n",
    "        return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7abf9f",
   "metadata": {},
   "source": [
    "### LCMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f30d3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run LCMA\n",
    "similarity_threshold = 0.1\n",
    "lcma = LCMA(similarity_threshold=similarity_threshold, min_clique_size=3, method = 'directed')\n",
    "lcma_routes = routes_dict.copy()\n",
    "clusters = lcma.find_route_clusters(lcma_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0ade9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n",
      "Nodes (Airports): ['PNQ', 'MAA', 'BOM', 'LHR', 'AMD', 'COK', 'IXB', 'DEL', 'LKO', 'HYD', 'CCU', 'KBL', 'BLR', 'GAU', 'DXB', 'GOI']\n",
      "Metrics:\n",
      "  size: 16\n",
      "  density: 0.29\n",
      "  avg_degree: 8.75\n",
      "  avg_weight: 5.54\n",
      "  max_weight: 7\n",
      "  total_flights: 388\n",
      "\n",
      "Cluster 1:\n",
      "Nodes (Airports): ['HRB', 'DAC', 'KIX', 'HGH', 'PEK', 'HKG', 'LHW', 'SZX', 'CAN', 'CTU', 'XIY', 'XNN', 'XMN', 'NNG', 'SHE', 'SHA', 'DLC', 'TYN', 'WUH', 'ICN', 'NGB', 'KMG', 'KWE', 'NKG', 'CKG', 'PUS', 'SYX', 'LAX', 'URC', 'KUL', 'NGO', 'CSX', 'ORD', 'SFO', 'NRT', 'CEB', 'LJG', 'WNZ', 'SIN', 'TPE', 'TNA', 'MNL', 'TSN', 'CGQ', 'FUK', 'BKK', 'PVG', 'FOC', 'KWL', 'CGO', 'HAK', 'TAO', 'INC']\n",
      "Metrics:\n",
      "  size: 53\n",
      "  density: 0.19\n",
      "  avg_degree: 20.19\n",
      "  avg_weight: 6.25\n",
      "  max_weight: 12\n",
      "  total_flights: 3342\n",
      "\n",
      "Cluster 2:\n",
      "Nodes (Airports): ['PER', 'SYD', 'SUB', 'DPS', 'SIN', 'JOG', 'HKG', 'AUH', 'CMB', 'ADL', 'BKK', 'CGK', 'BNE', 'AKL', 'WLG', 'CNS', 'KUL', 'MEL', 'HKT']\n",
      "Metrics:\n",
      "  size: 19\n",
      "  density: 0.24\n",
      "  avg_degree: 8.53\n",
      "  avg_weight: 7.04\n",
      "  max_weight: 13\n",
      "  total_flights: 570\n",
      "\n",
      "Cluster 3:\n",
      "Nodes (Airports): ['EWR', 'PRG', 'RDU', 'CUN', 'LAS', 'TPA', 'IAD', 'YUL', 'DUB', 'MEX', 'TUS', 'LAX', 'MSY', 'LGW', 'SJU', 'ORD', 'YVR', 'BRU', 'AMS', 'AUS', 'MTY', 'FRA', 'SAN', 'MXP', 'STL', 'DEN', 'GRU', 'OGG', 'MCO', 'SEA', 'FLL', 'YYZ', 'PDX', 'PMI', 'LIS', 'ORY', 'LGA', 'SJD', 'DTW', 'BNA', 'SYD', 'MIA', 'ATL', 'BOS', 'MUC', 'FCO', 'PHL', 'OPO', 'GVA', 'PHX', 'DFW', 'AGP', 'SLC', 'MSP', 'YYC', 'SFO', 'IAH', 'NRT', 'HNL', 'BCN', 'LHR', 'GDL', 'ABQ', 'AUH', 'CDG', 'MAD', 'GIG', 'EZE', 'JFK', 'MAN', 'VIE']\n",
      "Metrics:\n",
      "  size: 71\n",
      "  density: 0.09\n",
      "  avg_degree: 12.11\n",
      "  avg_weight: 6.51\n",
      "  max_weight: 20\n",
      "  total_flights: 2798\n",
      "\n",
      "Cluster 4:\n",
      "Nodes (Airports): ['HFE', 'CTU', 'CAN', 'XMN']\n",
      "Metrics:\n",
      "  size: 4\n",
      "  density: 0.92\n",
      "  avg_degree: 5.50\n",
      "  avg_weight: 5.91\n",
      "  max_weight: 7\n",
      "  total_flights: 65\n",
      "\n",
      "Cluster 5:\n",
      "Nodes (Airports): ['MIA', 'BOG', 'CLO']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 0.83\n",
      "  avg_degree: 3.33\n",
      "  avg_weight: 5.20\n",
      "  max_weight: 6\n",
      "  total_flights: 26\n",
      "\n",
      "Cluster 6:\n",
      "Nodes (Airports): ['NBO', 'BJM', 'KGL']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 0.67\n",
      "  avg_degree: 2.67\n",
      "  avg_weight: 6.50\n",
      "  max_weight: 7\n",
      "  total_flights: 26\n",
      "\n",
      "Cluster 7:\n",
      "Nodes (Airports): ['BHX', 'MAN', 'LGW', 'FUE', 'ACE']\n",
      "Metrics:\n",
      "  size: 5\n",
      "  density: 0.65\n",
      "  avg_degree: 5.20\n",
      "  avg_weight: 6.08\n",
      "  max_weight: 9\n",
      "  total_flights: 79\n",
      "\n",
      "Cluster 8:\n",
      "Nodes (Airports): ['HBE', 'JED', 'KWI']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 6.00\n",
      "  max_weight: 7\n",
      "  total_flights: 36\n",
      "\n",
      "Cluster 9:\n",
      "Nodes (Airports): ['LJG', 'JHG', 'KMG']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 7.17\n",
      "  max_weight: 10\n",
      "  total_flights: 43\n",
      "\n",
      "Cluster 10:\n",
      "Nodes (Airports): ['CPH', 'VIE', 'TXL']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 5.17\n",
      "  max_weight: 6\n",
      "  total_flights: 31\n",
      "\n",
      "Cluster 11:\n",
      "Nodes (Airports): ['CKG', 'XNN', 'CGO']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 6.00\n",
      "  max_weight: 7\n",
      "  total_flights: 36\n",
      "\n",
      "Cluster 12:\n",
      "Nodes (Airports): ['NKG', 'FOC', 'HAK']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 6.00\n",
      "  max_weight: 8\n",
      "  total_flights: 36\n",
      "\n",
      "Cluster 13:\n",
      "Nodes (Airports): ['TAO', 'PEK', 'NGB']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 5.00\n",
      "  max_weight: 5\n",
      "  total_flights: 30\n",
      "\n",
      "Cluster 14:\n",
      "Nodes (Airports): ['DXB', 'BAH', 'DOH']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 0.67\n",
      "  avg_degree: 2.67\n",
      "  avg_weight: 8.00\n",
      "  max_weight: 12\n",
      "  total_flights: 32\n",
      "\n",
      "Cluster 15:\n",
      "Nodes (Airports): ['LGA', 'YYZ', 'YUL', 'ORD']\n",
      "Metrics:\n",
      "  size: 4\n",
      "  density: 1.00\n",
      "  avg_degree: 6.00\n",
      "  avg_weight: 5.92\n",
      "  max_weight: 7\n",
      "  total_flights: 71\n",
      "\n",
      "Cluster 16:\n",
      "Nodes (Airports): ['LIS', 'AMS', 'LHR']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 1.00\n",
      "  avg_degree: 4.00\n",
      "  avg_weight: 6.50\n",
      "  max_weight: 8\n",
      "  total_flights: 39\n",
      "\n",
      "Cluster 17:\n",
      "Nodes (Airports): ['SMF', 'LAX', 'SEA']\n",
      "Metrics:\n",
      "  size: 3\n",
      "  density: 0.83\n",
      "  avg_degree: 3.33\n",
      "  avg_weight: 5.60\n",
      "  max_weight: 7\n",
      "  total_flights: 28\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for cluster in clusters:\n",
    "    print(f\"\\nCluster {cluster['cluster_id']}:\")\n",
    "    print(f\"Nodes (Airports): {cluster['nodes']}\")\n",
    "    print(\"Metrics:\")\n",
    "        # Get routes within cluster\n",
    "    for metric, value in cluster['metrics'].items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {metric}: {value}\")\n",
    "            \n",
    "#     routes = lcma.get_cluster_routes(set(cluster['nodes']))\n",
    "#     if routes:\n",
    "#         print(\"Routes (with frequencies):\")\n",
    "#         for route, weight in sorted(routes.items()):\n",
    "#             print(route, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46237c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcma_nodes = {\n",
    "    cluster['cluster_id'] : cluster['nodes']\n",
    "    for cluster in clusters\n",
    "}\n",
    "lcma_nodes_count = create_nodes_count(lcma_nodes)\n",
    "lcma_edges = {\n",
    "    cluster['cluster_id'] : list(lcma.get_cluster_routes(set(cluster['nodes'])).keys())\n",
    "    for cluster in clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cd55a",
   "metadata": {},
   "source": [
    "### Draw IHCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f2bbb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\lcam0.1.html'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(lcma_nodes.keys())\n",
    "L_e = len(lcma_edges.keys())\n",
    "\n",
    "# Add airport scatter points\n",
    "for i, key in enumerate(lcma_nodes.keys()):\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports cluster {key}\",\n",
    "        data_pair=lcma_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "\n",
    "for i, key in enumerate(lcma_edges.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({255 - 250*rate},160, {250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes cluster {key}\",\n",
    "        data_pair=lcma_edges[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity=0.4 + 0.6*rate, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=f\"Aiport and Routes (LCMA-{similarity_threshold})\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render(f'../echarts/RouteBased/lcam{similarity_threshold}.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18f659",
   "metadata": {},
   "source": [
    "## Divisive methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ce103",
   "metadata": {},
   "source": [
    "### Original girvan_newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06a52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities: 17\n",
      "(['ABQ', 'ABZ', 'ACE', 'ADD', 'ADL', 'AGP', 'AKL', 'ALB', 'ALC', 'ALG', 'AMS', 'AQP', 'ARN', 'ATH', 'ATL', 'AUA', 'AUH', 'AUS', 'AYT', 'BAH', 'BCN', 'BDL', 'BDO', 'BEG', 'BHM', 'BHX', 'BJM', 'BKI', 'BKK', 'BKO', 'BNA', 'BNE', 'BOG', 'BOS', 'BPN', 'BRS', 'BRU', 'BWI', 'CAK', 'CAN', 'CCS', 'CDG', 'CEB', 'CEI', 'CGK', 'CGN', 'CGO', 'CGQ', 'CHA', 'CHC', 'CHS', 'CJU', 'CKG', 'CKY', 'CLE', 'CLO', 'CLT', 'CMB', 'CMH', 'CMN', 'CNS', 'CNX', 'CPH', 'CPT', 'CSX', 'CTA', 'CTS', 'CTU', 'CUN', 'CUZ', 'CVG', 'CZM', 'DAC', 'DAR', 'DAY', 'DBV', 'DCA', 'DEN', 'DFW', 'DKR', 'DLA', 'DLC', 'DLM', 'DME', 'DMM', 'DOH', 'DPS', 'DRW', 'DTW', 'DUB', 'DUS', 'DXB', 'EBB', 'EDI', 'ELP', 'EMA', 'EWR', 'EZE', 'FAO', 'FCO', 'FIH', 'FLL', 'FLR', 'FOC', 'FRA', 'FRU', 'FUE', 'FUK', 'GDL', 'GIG', 'GLA', 'GMP', 'GRU', 'GSO', 'GSP', 'GUA', 'GVA', 'HAK', 'HAM', 'HBE', 'HEL', 'HER', 'HET', 'HFE', 'HGH', 'HKG', 'HKT', 'HLD', 'HND', 'HNL', 'HOU', 'HRB', 'HRG', 'HSV', 'HTN', 'IAD', 'IAH', 'IBZ', 'ICN', 'INC', 'IND', 'ISB', 'JAN', 'JAX', 'JED', 'JFK', 'JHG', 'JNB', 'JOG', 'JRO', 'JZH', 'KBV', 'KGL', 'KHG', 'KHH', 'KHN', 'KIX', 'KLO', 'KMG', 'KOA', 'KUL', 'KWE', 'KWI', 'KWL', 'LAS', 'LAX', 'LCA', 'LED', 'LGA', 'LGK', 'LGW', 'LHE', 'LHR', 'LHW', 'LIH', 'LIM', 'LIS', 'LJG', 'LPA', 'LXA', 'LYS', 'MAD', 'MAN', 'MAR', 'MCI', 'MCO', 'MCT', 'MDE', 'MDW', 'MEL', 'MEM', 'MEX', 'MFM', 'MIA', 'MKE', 'MLE', 'MNL', 'MRS', 'MSP', 'MSY', 'MTY', 'MUC', 'MVD', 'MXP', 'NBO', 'NGB', 'NGO', 'NKG', 'NNG', 'NRT', 'NSI', 'OGG', 'OKA', 'OKC', 'OPO', 'ORD', 'ORF', 'ORY', 'OSL', 'OSS', 'OTP', 'PBI', 'PDX', 'PEK', 'PEN', 'PER', 'PFO', 'PHL', 'PHX', 'PIT', 'PKU', 'PMI', 'PMV', 'PNH', 'PNS', 'PPS', 'PPT', 'PRG', 'PSP', 'PTY', 'PUS', 'PVG', 'PVR', 'RAK', 'RDU', 'RGN', 'RIC', 'RNO', 'RSW', 'RUH', 'SAN', 'SAT', 'SAV', 'SCL', 'SDF', 'SDJ', 'SEA', 'SFO', 'SGN', 'SHA', 'SHE', 'SIN', 'SJC', 'SJD', 'SJU', 'SJW', 'SKG', 'SLC', 'SMF', 'SRQ', 'SSG', 'SSH', 'STL', 'STR', 'STT', 'SUB', 'SVQ', 'SYD', 'SYX', 'SZX', 'TAO', 'TFN', 'TFS', 'TIA', 'TIV', 'TLS', 'TNA', 'TPA', 'TPE', 'TSA', 'TSN', 'TUS', 'TXL', 'TYN', 'TYS', 'URC', 'VIE', 'VLC', 'VQS', 'VRN', 'VVO', 'WAW', 'WDH', 'WLG', 'WNZ', 'WUH', 'XIY', 'XMN', 'XNA', 'XNN', 'YEG', 'YNT', 'YUL', 'YVR', 'YYC', 'YYZ', 'YZF', 'ZRH', 'ZUH'], ['HRE', 'LLW', 'LUN'], ['ABJ', 'ACC', 'COO', 'LFW', 'LOS', 'NIM', 'OUA'], ['GYE', 'UIO'], ['AMD', 'BLR', 'BOM', 'CCU', 'CJB', 'COK', 'DEL', 'GAU', 'GOI', 'HYD', 'IDR', 'IXA', 'IXB', 'IXE', 'IXJ', 'IXR', 'IXZ', 'JAI', 'KBL', 'KTM', 'LKO', 'MAA', 'NAG', 'PAT', 'PNQ', 'SXR', 'TRV', 'VNS'], ['FNA', 'ROB'], ['YWK', 'YZV'], ['LPB', 'VVI'], ['BEL', 'MAO', 'STM'], ['FDF', 'PTP', 'SLU'], ['TIP', 'TUN'], ['IKA', 'IST'], ['CWB', 'POA'], ['ALA', 'TSE'], ['OVB', 'SVX'], ['DZA', 'HAH'], ['DOM', 'SXM'])\n",
      "Number of communities: 18\n",
      "(['ABQ', 'ABZ', 'ACE', 'ADD', 'AGP', 'ALB', 'ALC', 'ALG', 'AMS', 'AQP', 'ARN', 'ATH', 'ATL', 'AUA', 'AUH', 'AUS', 'AYT', 'BAH', 'BCN', 'BDL', 'BEG', 'BHM', 'BHX', 'BJM', 'BKO', 'BNA', 'BOG', 'BOS', 'BRS', 'BRU', 'BWI', 'CAK', 'CCS', 'CDG', 'CGN', 'CHA', 'CHS', 'CKY', 'CLE', 'CLO', 'CLT', 'CMH', 'CMN', 'CPH', 'CPT', 'CTA', 'CUN', 'CUZ', 'CVG', 'CZM', 'DAR', 'DAY', 'DBV', 'DCA', 'DEN', 'DFW', 'DKR', 'DLA', 'DLM', 'DME', 'DMM', 'DOH', 'DTW', 'DUB', 'DUS', 'DXB', 'EBB', 'EDI', 'ELP', 'EMA', 'EWR', 'EZE', 'FAO', 'FCO', 'FIH', 'FLL', 'FLR', 'FRA', 'FRU', 'FUE', 'GDL', 'GIG', 'GLA', 'GRU', 'GSO', 'GSP', 'GUA', 'GVA', 'HAM', 'HBE', 'HEL', 'HER', 'HNL', 'HOU', 'HRG', 'HSV', 'IAD', 'IAH', 'IBZ', 'IND', 'ISB', 'JAN', 'JAX', 'JED', 'JFK', 'JNB', 'JRO', 'KGL', 'KOA', 'KWI', 'LAS', 'LAX', 'LCA', 'LED', 'LGA', 'LGW', 'LHE', 'LHR', 'LIH', 'LIM', 'LIS', 'LPA', 'LYS', 'MAD', 'MAN', 'MAR', 'MCI', 'MCO', 'MCT', 'MDE', 'MDW', 'MEM', 'MEX', 'MIA', 'MKE', 'MRS', 'MSP', 'MSY', 'MTY', 'MUC', 'MVD', 'MXP', 'NBO', 'NSI', 'OGG', 'OKC', 'OPO', 'ORD', 'ORF', 'ORY', 'OSL', 'OSS', 'OTP', 'PBI', 'PDX', 'PFO', 'PHL', 'PHX', 'PIT', 'PMI', 'PMV', 'PNS', 'PPT', 'PRG', 'PSP', 'PTY', 'PVR', 'RAK', 'RDU', 'RIC', 'RNO', 'RSW', 'RUH', 'SAN', 'SAT', 'SAV', 'SCL', 'SDF', 'SEA', 'SFO', 'SJC', 'SJD', 'SJU', 'SKG', 'SLC', 'SMF', 'SRQ', 'SSG', 'SSH', 'STL', 'STR', 'STT', 'SVQ', 'TFN', 'TFS', 'TIA', 'TIV', 'TLS', 'TPA', 'TUS', 'TXL', 'TYS', 'VIE', 'VLC', 'VQS', 'VRN', 'WAW', 'WDH', 'XNA', 'YEG', 'YUL', 'YVR', 'YYC', 'YYZ', 'YZF', 'ZRH'], ['ADL', 'AKL', 'BDO', 'BKI', 'BKK', 'BNE', 'BPN', 'CAN', 'CEB', 'CEI', 'CGK', 'CGO', 'CGQ', 'CHC', 'CJU', 'CKG', 'CMB', 'CNS', 'CNX', 'CSX', 'CTS', 'CTU', 'DAC', 'DLC', 'DPS', 'DRW', 'FOC', 'FUK', 'GMP', 'HAK', 'HET', 'HFE', 'HGH', 'HKG', 'HKT', 'HLD', 'HND', 'HRB', 'HTN', 'ICN', 'INC', 'JHG', 'JOG', 'JZH', 'KBV', 'KHG', 'KHH', 'KHN', 'KIX', 'KLO', 'KMG', 'KUL', 'KWE', 'KWL', 'LGK', 'LHW', 'LJG', 'LXA', 'MEL', 'MFM', 'MLE', 'MNL', 'NGB', 'NGO', 'NKG', 'NNG', 'NRT', 'OKA', 'PEK', 'PEN', 'PER', 'PKU', 'PNH', 'PPS', 'PUS', 'PVG', 'RGN', 'SDJ', 'SGN', 'SHA', 'SHE', 'SIN', 'SJW', 'SUB', 'SYD', 'SYX', 'SZX', 'TAO', 'TNA', 'TPE', 'TSA', 'TSN', 'TYN', 'URC', 'VVO', 'WLG', 'WNZ', 'WUH', 'XIY', 'XMN', 'XNN', 'YNT', 'ZUH'], ['HRE', 'LLW', 'LUN'], ['ABJ', 'ACC', 'COO', 'LFW', 'LOS', 'NIM', 'OUA'], ['GYE', 'UIO'], ['AMD', 'BLR', 'BOM', 'CCU', 'CJB', 'COK', 'DEL', 'GAU', 'GOI', 'HYD', 'IDR', 'IXA', 'IXB', 'IXE', 'IXJ', 'IXR', 'IXZ', 'JAI', 'KBL', 'KTM', 'LKO', 'MAA', 'NAG', 'PAT', 'PNQ', 'SXR', 'TRV', 'VNS'], ['FNA', 'ROB'], ['YWK', 'YZV'], ['LPB', 'VVI'], ['BEL', 'MAO', 'STM'], ['FDF', 'PTP', 'SLU'], ['TIP', 'TUN'], ['IKA', 'IST'], ['CWB', 'POA'], ['ALA', 'TSE'], ['OVB', 'SVX'], ['DZA', 'HAH'], ['DOM', 'SXM'])\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms.community import girvan_newman\n",
    "import itertools\n",
    "\n",
    "# iteration method\n",
    "iteration = 2\n",
    "comp = girvan_newman(Community.copy())\n",
    "for communities in itertools.islice(comp, iteration):\n",
    "    print(f'Number of communities: {len(communities)}')\n",
    "    print(tuple(sorted(c) for c in communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d83a4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities: 17\n",
      "(['ABQ', 'ABZ', 'ACE', 'ADD', 'ADL', 'AGP', 'AKL', 'ALB', 'ALC', 'ALG', 'AMS', 'AQP', 'ARN', 'ATH', 'ATL', 'AUA', 'AUH', 'AUS', 'AYT', 'BAH', 'BCN', 'BDL', 'BDO', 'BEG', 'BHM', 'BHX', 'BJM', 'BKI', 'BKK', 'BKO', 'BNA', 'BNE', 'BOG', 'BOS', 'BPN', 'BRS', 'BRU', 'BWI', 'CAK', 'CAN', 'CCS', 'CDG', 'CEB', 'CEI', 'CGK', 'CGN', 'CGO', 'CGQ', 'CHA', 'CHC', 'CHS', 'CJU', 'CKG', 'CKY', 'CLE', 'CLO', 'CLT', 'CMB', 'CMH', 'CMN', 'CNS', 'CNX', 'CPH', 'CPT', 'CSX', 'CTA', 'CTS', 'CTU', 'CUN', 'CUZ', 'CVG', 'CZM', 'DAC', 'DAR', 'DAY', 'DBV', 'DCA', 'DEN', 'DFW', 'DKR', 'DLA', 'DLC', 'DLM', 'DME', 'DMM', 'DOH', 'DPS', 'DRW', 'DTW', 'DUB', 'DUS', 'DXB', 'EBB', 'EDI', 'ELP', 'EMA', 'EWR', 'EZE', 'FAO', 'FCO', 'FIH', 'FLL', 'FLR', 'FOC', 'FRA', 'FRU', 'FUE', 'FUK', 'GDL', 'GIG', 'GLA', 'GMP', 'GRU', 'GSO', 'GSP', 'GUA', 'GVA', 'HAK', 'HAM', 'HBE', 'HEL', 'HER', 'HET', 'HFE', 'HGH', 'HKG', 'HKT', 'HLD', 'HND', 'HNL', 'HOU', 'HRB', 'HRG', 'HSV', 'HTN', 'IAD', 'IAH', 'IBZ', 'ICN', 'INC', 'IND', 'ISB', 'JAN', 'JAX', 'JED', 'JFK', 'JHG', 'JNB', 'JOG', 'JRO', 'JZH', 'KBV', 'KGL', 'KHG', 'KHH', 'KHN', 'KIX', 'KLO', 'KMG', 'KOA', 'KUL', 'KWE', 'KWI', 'KWL', 'LAS', 'LAX', 'LCA', 'LED', 'LGA', 'LGK', 'LGW', 'LHE', 'LHR', 'LHW', 'LIH', 'LIM', 'LIS', 'LJG', 'LPA', 'LXA', 'LYS', 'MAD', 'MAN', 'MAR', 'MCI', 'MCO', 'MCT', 'MDE', 'MDW', 'MEL', 'MEM', 'MEX', 'MFM', 'MIA', 'MKE', 'MLE', 'MNL', 'MRS', 'MSP', 'MSY', 'MTY', 'MUC', 'MVD', 'MXP', 'NBO', 'NGB', 'NGO', 'NKG', 'NNG', 'NRT', 'NSI', 'OGG', 'OKA', 'OKC', 'OPO', 'ORD', 'ORF', 'ORY', 'OSL', 'OSS', 'OTP', 'PBI', 'PDX', 'PEK', 'PEN', 'PER', 'PFO', 'PHL', 'PHX', 'PIT', 'PKU', 'PMI', 'PMV', 'PNH', 'PNS', 'PPS', 'PPT', 'PRG', 'PSP', 'PTY', 'PUS', 'PVG', 'PVR', 'RAK', 'RDU', 'RGN', 'RIC', 'RNO', 'RSW', 'RUH', 'SAN', 'SAT', 'SAV', 'SCL', 'SDF', 'SDJ', 'SEA', 'SFO', 'SGN', 'SHA', 'SHE', 'SIN', 'SJC', 'SJD', 'SJU', 'SJW', 'SKG', 'SLC', 'SMF', 'SRQ', 'SSG', 'SSH', 'STL', 'STR', 'STT', 'SUB', 'SVQ', 'SYD', 'SYX', 'SZX', 'TAO', 'TFN', 'TFS', 'TIA', 'TIV', 'TLS', 'TNA', 'TPA', 'TPE', 'TSA', 'TSN', 'TUS', 'TXL', 'TYN', 'TYS', 'URC', 'VIE', 'VLC', 'VQS', 'VRN', 'VVO', 'WAW', 'WDH', 'WLG', 'WNZ', 'WUH', 'XIY', 'XMN', 'XNA', 'XNN', 'YEG', 'YNT', 'YUL', 'YVR', 'YYC', 'YYZ', 'YZF', 'ZRH', 'ZUH'], ['HRE', 'LLW', 'LUN'], ['ABJ', 'ACC', 'COO', 'LFW', 'LOS', 'NIM', 'OUA'], ['GYE', 'UIO'], ['AMD', 'BLR', 'BOM', 'CCU', 'CJB', 'COK', 'DEL', 'GAU', 'GOI', 'HYD', 'IDR', 'IXA', 'IXB', 'IXE', 'IXJ', 'IXR', 'IXZ', 'JAI', 'KBL', 'KTM', 'LKO', 'MAA', 'NAG', 'PAT', 'PNQ', 'SXR', 'TRV', 'VNS'], ['FNA', 'ROB'], ['YWK', 'YZV'], ['LPB', 'VVI'], ['BEL', 'MAO', 'STM'], ['FDF', 'PTP', 'SLU'], ['TIP', 'TUN'], ['IKA', 'IST'], ['CWB', 'POA'], ['ALA', 'TSE'], ['OVB', 'SVX'], ['DZA', 'HAH'], ['DOM', 'SXM'])\n",
      "Number of communities: 18\n",
      "(['ABQ', 'ABZ', 'ACE', 'ADD', 'AGP', 'ALB', 'ALC', 'ALG', 'AMS', 'AQP', 'ARN', 'ATH', 'ATL', 'AUA', 'AUH', 'AUS', 'AYT', 'BAH', 'BCN', 'BDL', 'BEG', 'BHM', 'BHX', 'BJM', 'BKO', 'BNA', 'BOG', 'BOS', 'BRS', 'BRU', 'BWI', 'CAK', 'CCS', 'CDG', 'CGN', 'CHA', 'CHS', 'CKY', 'CLE', 'CLO', 'CLT', 'CMH', 'CMN', 'CPH', 'CPT', 'CTA', 'CUN', 'CUZ', 'CVG', 'CZM', 'DAR', 'DAY', 'DBV', 'DCA', 'DEN', 'DFW', 'DKR', 'DLA', 'DLM', 'DME', 'DMM', 'DOH', 'DTW', 'DUB', 'DUS', 'DXB', 'EBB', 'EDI', 'ELP', 'EMA', 'EWR', 'EZE', 'FAO', 'FCO', 'FIH', 'FLL', 'FLR', 'FRA', 'FRU', 'FUE', 'GDL', 'GIG', 'GLA', 'GRU', 'GSO', 'GSP', 'GUA', 'GVA', 'HAM', 'HBE', 'HEL', 'HER', 'HNL', 'HOU', 'HRG', 'HSV', 'IAD', 'IAH', 'IBZ', 'IND', 'ISB', 'JAN', 'JAX', 'JED', 'JFK', 'JNB', 'JRO', 'KGL', 'KOA', 'KWI', 'LAS', 'LAX', 'LCA', 'LED', 'LGA', 'LGW', 'LHE', 'LHR', 'LIH', 'LIM', 'LIS', 'LPA', 'LYS', 'MAD', 'MAN', 'MAR', 'MCI', 'MCO', 'MCT', 'MDE', 'MDW', 'MEM', 'MEX', 'MIA', 'MKE', 'MRS', 'MSP', 'MSY', 'MTY', 'MUC', 'MVD', 'MXP', 'NBO', 'NSI', 'OGG', 'OKC', 'OPO', 'ORD', 'ORF', 'ORY', 'OSL', 'OSS', 'OTP', 'PBI', 'PDX', 'PFO', 'PHL', 'PHX', 'PIT', 'PMI', 'PMV', 'PNS', 'PPT', 'PRG', 'PSP', 'PTY', 'PVR', 'RAK', 'RDU', 'RIC', 'RNO', 'RSW', 'RUH', 'SAN', 'SAT', 'SAV', 'SCL', 'SDF', 'SEA', 'SFO', 'SJC', 'SJD', 'SJU', 'SKG', 'SLC', 'SMF', 'SRQ', 'SSG', 'SSH', 'STL', 'STR', 'STT', 'SVQ', 'TFN', 'TFS', 'TIA', 'TIV', 'TLS', 'TPA', 'TUS', 'TXL', 'TYS', 'VIE', 'VLC', 'VQS', 'VRN', 'WAW', 'WDH', 'XNA', 'YEG', 'YUL', 'YVR', 'YYC', 'YYZ', 'YZF', 'ZRH'], ['ADL', 'AKL', 'BDO', 'BKI', 'BKK', 'BNE', 'BPN', 'CAN', 'CEB', 'CEI', 'CGK', 'CGO', 'CGQ', 'CHC', 'CJU', 'CKG', 'CMB', 'CNS', 'CNX', 'CSX', 'CTS', 'CTU', 'DAC', 'DLC', 'DPS', 'DRW', 'FOC', 'FUK', 'GMP', 'HAK', 'HET', 'HFE', 'HGH', 'HKG', 'HKT', 'HLD', 'HND', 'HRB', 'HTN', 'ICN', 'INC', 'JHG', 'JOG', 'JZH', 'KBV', 'KHG', 'KHH', 'KHN', 'KIX', 'KLO', 'KMG', 'KUL', 'KWE', 'KWL', 'LGK', 'LHW', 'LJG', 'LXA', 'MEL', 'MFM', 'MLE', 'MNL', 'NGB', 'NGO', 'NKG', 'NNG', 'NRT', 'OKA', 'PEK', 'PEN', 'PER', 'PKU', 'PNH', 'PPS', 'PUS', 'PVG', 'RGN', 'SDJ', 'SGN', 'SHA', 'SHE', 'SIN', 'SJW', 'SUB', 'SYD', 'SYX', 'SZX', 'TAO', 'TNA', 'TPE', 'TSA', 'TSN', 'TYN', 'URC', 'VVO', 'WLG', 'WNZ', 'WUH', 'XIY', 'XMN', 'XNN', 'YNT', 'ZUH'], ['HRE', 'LLW', 'LUN'], ['ABJ', 'ACC', 'COO', 'LFW', 'LOS', 'NIM', 'OUA'], ['GYE', 'UIO'], ['AMD', 'BLR', 'BOM', 'CCU', 'CJB', 'COK', 'DEL', 'GAU', 'GOI', 'HYD', 'IDR', 'IXA', 'IXB', 'IXE', 'IXJ', 'IXR', 'IXZ', 'JAI', 'KBL', 'KTM', 'LKO', 'MAA', 'NAG', 'PAT', 'PNQ', 'SXR', 'TRV', 'VNS'], ['FNA', 'ROB'], ['YWK', 'YZV'], ['LPB', 'VVI'], ['BEL', 'MAO', 'STM'], ['FDF', 'PTP', 'SLU'], ['TIP', 'TUN'], ['IKA', 'IST'], ['CWB', 'POA'], ['ALA', 'TSE'], ['OVB', 'SVX'], ['DZA', 'HAH'], ['DOM', 'SXM'])\n"
     ]
    }
   ],
   "source": [
    "# stop when the number of communities is greater than k\n",
    "k = 18\n",
    "comp = girvan_newman(Community.copy())\n",
    "limited = itertools.takewhile(lambda c: len(c) <= k, comp)\n",
    "for communities in limited:\n",
    "    print(f'Number of communities: {len(communities)}')\n",
    "    print(tuple(sorted(c) for c in communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8b07a",
   "metadata": {},
   "source": [
    "### Modified girvan_newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "000edbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def girvan_newman_(G, most_valuable_edge=None):\n",
    "    \"\"\"\n",
    "    Repeatedly remove edges from the graph to detect communities via the Girvan-Newman method.\n",
    "    This modified version supports both directed and undirected graphs.\n",
    "\n",
    "    The GirvanNewman algorithm detects communities by progressively removing edges from the\n",
    "    original graph. The algorithm removes the \"most valuable\" edges first. After each removal,\n",
    "    it measures the number of connected components in the graph.\n",
    "\n",
    "    Args:\n",
    "        G: NetworkX graph or directed graph (DiGraph)\n",
    "        most_valuable_edge: Optional function that takes a graph as input and returns\n",
    "            an edge to be removed. If not specified, edge betweenness centrality is used.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A 2-tuple for each iteration:\n",
    "            - First element is the set of communities (as frozensets of nodes)\n",
    "            - Second element contains edges removed in this iteration\n",
    "\n",
    "    Note:\n",
    "        This is a modified version of the original NetworkX implementation with:\n",
    "        1. Support for directed graphs (converts to undirected internally for component analysis)\n",
    "        2. Returns information about removed edges for each iteration\n",
    "    \"\"\"\n",
    "    if G.number_of_edges() == 0:\n",
    "        yield tuple(nx.connected_components(G))\n",
    "        return\n",
    "    # If no function is provided for computing the most valuable edge,\n",
    "    # use the edge betweenness centrality.\n",
    "    if most_valuable_edge is None:\n",
    "\n",
    "        def most_valuable_edge(G):\n",
    "            \"\"\"Returns the edge with the highest betweenness centrality\n",
    "            in the graph `G`.\n",
    "\n",
    "            \"\"\"\n",
    "            # We have guaranteed that the graph is non-empty, so this\n",
    "            # dictionary will never be empty.\n",
    "            \n",
    "            # Calculate weighted betweenness centrality using edge weights\n",
    "            # weight='weight' tells NetworkX to use Dijkstra's algorithm with the 'weight' edge attribute\n",
    "            betweenness = nx.edge_betweenness_centrality(G, weight=\"weight\")\n",
    "            return max(betweenness, key=betweenness.get)\n",
    "\n",
    "    # The copy of G here must include the edge weight data.\n",
    "    g = G.copy()\n",
    "    \n",
    "    # Remove self-loops as they don't affect community structure\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    while g.number_of_edges() > 0:\n",
    "        yield _without_most_central_edges(g, most_valuable_edge)\n",
    "    \n",
    "def _without_most_central_edges(G, most_valuable_edge):\n",
    "    \"\"\"\n",
    "    Removes edges from graph until the number of connected components increases.\n",
    "    \n",
    "    This function implements one iteration of the Girvan-Newman algorithm by removing\n",
    "    edges until the graph splits into more components. It tracks all edges removed\n",
    "    during the process.\n",
    "\n",
    "    Args:\n",
    "        G: NetworkX graph or directed graph (will be modified in-place)\n",
    "        most_valuable_edge: Function that takes a graph and returns the next edge to remove\n",
    "\n",
    "    Returns:\n",
    "        tuple: A 2-tuple containing:\n",
    "            - The new connected components after edge removal (as frozensets of nodes)\n",
    "            - List of edges removed during this iteration\n",
    "\n",
    "    Note:\n",
    "        For directed graphs, component analysis is performed on the undirected version,\n",
    "        but edge removal is done on the original directed graph.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get initial number of components (using undirected version for directed graphs)\n",
    "    original_num_components = nx.number_connected_components(G.to_undirected())\n",
    "    num_new_components = original_num_components\n",
    "    edges_removed = []\n",
    "    \n",
    "    # Remove edges until we get more components\n",
    "    while num_new_components <= original_num_components:\n",
    "        edge = most_valuable_edge(G)\n",
    "        edges_removed.append(edge)\n",
    "        G.remove_edge(*edge)\n",
    "        new_components = tuple(nx.connected_components(G.to_undirected()))\n",
    "        num_new_components = len(new_components)\n",
    "    return new_components, edges_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db878e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities: 17\n",
      "Number of Removed edges: 101\n",
      "-----------------------\n",
      "Number of communities: 18\n",
      "Number of Removed edges: 83\n",
      "-----------------------\n",
      "Number of communities: 19\n",
      "Number of Removed edges: 11\n",
      "-----------------------\n",
      "Number of communities: 20\n",
      "Number of Removed edges: 54\n",
      "-----------------------\n",
      "Number of communities: 21\n",
      "Number of Removed edges: 43\n",
      "-----------------------\n",
      "Number of communities: 22\n",
      "Number of Removed edges: 12\n",
      "-----------------------\n",
      "Number of communities: 23\n",
      "Number of Removed edges: 2\n",
      "-----------------------\n",
      "Number of communities: 24\n",
      "Number of Removed edges: 1\n",
      "-----------------------\n",
      "Number of communities: 25\n",
      "Number of Removed edges: 10\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "k = 25\n",
    "comp = girvan_newman_(Community.copy())\n",
    "limited = itertools.takewhile(lambda c: len(c[0]) <= k, comp)\n",
    "divi_edges = {}\n",
    "for i,communities in enumerate(limited):\n",
    "    divi_edges[f'Removed-{i}({len(communities[1])})'] = communities[1]\n",
    "    print(f'Number of communities: {len(communities[0])}')\n",
    "    print(f'Number of Removed edges: {len(communities[1])}')\n",
    "    print('-----------------------')\n",
    "\n",
    "removed_list = [edge for removed in divi_edges.values() for edge in removed]\n",
    "divi_edges['Reserved'] = list(set(routes_list) - set(removed_list))\n",
    "    \n",
    "divi_nodes = {\n",
    "    f'Community-{i}': list(community)\n",
    "    for i, community in enumerate(communities[0])\n",
    "}\n",
    "divi_nodes_count = create_nodes_count(divi_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c5b0f",
   "metadata": {},
   "source": [
    "### Draw Divisive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fede5022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\laoth\\\\Desktop\\\\study\\\\web\\\\echarts\\\\RouteBased\\\\divisive.html'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Geo object\n",
    "c = Geo(init_opts=opts.InitOpts(width=\"1600px\", height=\"800px\")) # Full the screen\n",
    "c.add_schema(maptype=\"world\")\n",
    "\n",
    "L_n = len(divi_nodes.keys())\n",
    "L_e = len(divi_edges.keys())\n",
    "\n",
    "# Add airport scatter points\n",
    "for i, key in enumerate(divi_nodes.keys()):\n",
    "    rate = i/L_n\n",
    "    color = f\"rgb({255 - 250*rate},0, 0)\"\n",
    "    c.add(\n",
    "        f\"Airports {key}\",\n",
    "        data_pair=divi_nodes_count[key],\n",
    "        type_=ChartType.EFFECT_SCATTER,\n",
    "        color=color,\n",
    "        symbol_size=3,\n",
    "    )\n",
    "\n",
    "for i, key in enumerate(divi_edges.keys()):\n",
    "    # Add airline routes for different ranges\n",
    "    rate = i/L_e\n",
    "    color = f\"rgb({250*rate},160, {255 - 250*rate})\"\n",
    "    c.add(\n",
    "        f\"Routes {key}\",\n",
    "        data_pair=divi_edges[key],  # Replace with your route filtering function\n",
    "        type_=ChartType.LINES,\n",
    "        symbol_size=0,\n",
    "        effect_opts=opts.EffectOpts(\n",
    "            symbol=SymbolType.ARROW, symbol_size=3, color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "        linestyle_opts=opts.LineStyleOpts(\n",
    "            width=0.1, curve=0.4, opacity= 1 - 0.6*rate, type_=\"solid\",color=color,  # Dynamic RGB color\n",
    "        ),\n",
    "    )\n",
    "\n",
    "c.set_series_opts(label_opts=opts.LabelOpts(is_show=False))\n",
    "c.set_global_opts(title_opts=opts.TitleOpts(title=f\"Aiport and Routes (Girvan and Newman Algorithm)\",pos_left = 'center'),\n",
    "                  legend_opts = opts.LegendOpts(type_ = 'scroll',orient = 'vertical',page_button_position = 'start',\n",
    "                                               pos_left = 'left'))\n",
    "c.render(f'../echarts/RouteBased/divisive.html') # save as .html\n",
    "# c.render_notebook() # if you want to display the graph in notebook, add this line, and set (width=\"900px\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bee789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "765.323px",
    "left": "10px",
    "top": "150px",
    "width": "270.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
